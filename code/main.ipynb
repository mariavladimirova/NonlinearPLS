{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T21:24:38.506749Z",
     "start_time": "2017-10-23T21:24:38.496980Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T21:12:36.837002Z",
     "start_time": "2017-10-23T21:12:36.818930Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaling(X, Y):\n",
    "    \"\"\" Center X, Y and scale\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        X, Y, x_mean, y_mean, x_std, y_std\n",
    "    \"\"\"\n",
    "    # center\n",
    "    x_mean = X.mean(axis=0)\n",
    "    X -= x_mean\n",
    "    y_mean = Y.mean(axis=0)\n",
    "    Y -= y_mean\n",
    "    # scale\n",
    "    x_std = X.std(axis=0, ddof=1)\n",
    "    x_std[x_std == 0.0] = 1.0\n",
    "    X /= x_std\n",
    "    y_std = Y.std(axis=0, ddof=1)\n",
    "    y_std[y_std == 0.0] = 1.0\n",
    "    Y /= y_std\n",
    "    return X, Y, x_mean, y_mean, x_std, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T21:26:14.512458Z",
     "start_time": "2017-10-23T21:26:14.471392Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nipals(X, Y, max_iter=500, tol=1e-06):\n",
    "    \"\"\"Inner loop of the iterative NIPALS algorithm.\n",
    "    Provides an alternative to the svd(X'Y); returns the first left and right\n",
    "    singular vectors of X'Y.  See PLS for the meaning of the parameters.  It is\n",
    "    similar to the Power method for determining the eigenvectors and\n",
    "    eigenvalues of a X'Y.\n",
    "    \n",
    "    y_score - U\n",
    "    y_weights - C\n",
    "    x_score - T\n",
    "    x_weights - W\n",
    "    \n",
    "    Return: vectors w, c\n",
    "    \"\"\"\n",
    "    # 1: initialization of u\n",
    "    u = Y[:, [0]]\n",
    "# TEST IT!!!!\n",
    "    t_old = 0\n",
    "    ite = 1\n",
    "    eps = np.finfo(X.dtype).eps\n",
    "    # Inner loop of the Wold algo.\n",
    "    while True:\n",
    "        # w = X^T u / (u^T u)\n",
    "        w = np.dot(X.T, u) / np.dot(u.T, u)\n",
    "        \n",
    "        # If u only has zeros w will only have zeros. In\n",
    "        # this case add an epsilon to converge to a more acceptable\n",
    "        # solution\n",
    "        if np.dot(w.T, w) < eps:\n",
    "            w += eps\n",
    "        # w = w / |w|\n",
    "        w /= (np.sqrt(np.dot(w.T, w)) + eps)\n",
    "        \n",
    "        # t = Xw\n",
    "        t = np.dot(X, w)\n",
    "        \n",
    "        # c = Y^T t / (t^T t)\n",
    "        c = np.dot(Y.T, t) / np.dot(t.T, t)\n",
    "        \n",
    "        # c = c / |c|\n",
    "        c /= np.sqrt(np.dot(c.T, c)) + eps\n",
    "\n",
    "        # u = Yc\n",
    "# ????? (TEST IT!!!!)\n",
    "        u = np.dot(Y, c) / (np.dot(c.T, c) + eps)\n",
    "        \n",
    "        # 10: convergence of t\n",
    "        t_diff = t - t_old\n",
    "        if np.dot(t_diff.T, t_diff) < tol or Y.shape[1] == 1:\n",
    "            break \n",
    "        if ite == max_iter:\n",
    "            warnings.warn('Maximum number of iterations reached')\n",
    "            break\n",
    "        t_old = t\n",
    "        ite += 1\n",
    "    return w, c, ite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import svd_flip\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.utils import check_array, check_consistent_length\n",
    "from sklearn.externals import six\n",
    "\n",
    "import warnings\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from scipy import linalg\n",
    "from sklearn.utils.validation import check_is_fitted, FLOAT_DTYPES\n",
    "\n",
    "pinv2_args = {'check_finite': False}\n",
    "\n",
    "\n",
    "class _PLS(six.with_metaclass(ABCMeta), BaseEstimator, TransformerMixin,\n",
    "           RegressorMixin):\n",
    "    \"\"\"\n",
    "    Partial Least Squares (PLS)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self, n_components=2, algorithm=\"nipals\", max_iter=500, tol=1e-06):\n",
    "        self.n_components = n_components\n",
    "        self.algorithm = algorithm\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Fit model to data.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # copy since this will contains the residuals (deflated) matrices\n",
    "        check_consistent_length(X, Y)\n",
    "        X = check_array(X, dtype=np.float64, copy=True)\n",
    "        Y = check_array(Y, dtype=np.float64, copy=True, ensure_2d=False)\n",
    "        if Y.ndim == 1:\n",
    "            Y = Y.reshape(-1, 1)\n",
    "\n",
    "        n, p = X.shape\n",
    "        q = Y.shape[1]\n",
    "\n",
    "        if self.n_components < 1 or self.n_components > p:\n",
    "            raise ValueError('Invalid number of components: %d' %\n",
    "                             self.n_components)\n",
    "        if self.algorithm not in (\"nipals\", \"nipals_nonlinear\"):\n",
    "            raise ValueError(\"\"\"Got algorithm %s when only \n",
    "                            'nipals' are known\"\"\" % self.algorithm)\n",
    "        # Scale (in place)\n",
    "        X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_ = (\n",
    "            scaling(X, Y))\n",
    "        # Residuals (deflated) matrices\n",
    "        Xk = X\n",
    "        Yk = Y\n",
    "        # Results matrices\n",
    "        self.T = np.zeros((n, self.n_components))\n",
    "        self.U = np.zeros((n, self.n_components))\n",
    "        self.W = np.zeros((p, self.n_components))\n",
    "        self.C = np.zeros((q, self.n_components))\n",
    "        self.P = np.zeros((p, self.n_components))\n",
    "        self.Q = np.zeros((q, self.n_components))\n",
    "        self.n_iter_ = []\n",
    "\n",
    "        \n",
    "        # NIPALS algo: outer loop, over components\n",
    "        for k in range(self.n_components):\n",
    "            if np.all(np.dot(Yk.T, Yk) < np.finfo(np.double).eps):\n",
    "                # Yk constant\n",
    "                warnings.warn('Y residual constant at iteration %s' % k)\n",
    "                break\n",
    "            # 1) weights estimation (inner loop)\n",
    "            # -----------------------------------\n",
    "            w, c, n_iter_ = nipals(X=Xk, Y=Yk, max_iter=self.max_iter,\\\n",
    "                        tol=self.tol)\n",
    "            self.n_iter_.append(n_iter_)\n",
    "            \n",
    "            # Forces sign stability of x_weights and y_weights\n",
    "            # Sign undeterminacy issue from svd if algorithm == \"svd\"\n",
    "            # and from platform dependent computation if algorithm == 'nipals'\n",
    "            w, c = svd_flip(w, c.T)\n",
    "            c = c.T\n",
    "            # compute scores\n",
    "            t = np.dot(Xk, w)\n",
    "            y_ss = np.dot(c.T, c) + np.finfo(np.double).eps\n",
    "            u = np.dot(Yk, c) / y_ss\n",
    "            \n",
    "            # test for null variance\n",
    "            if np.dot(t.T, t) < np.finfo(np.double).eps:\n",
    "                warnings.warn('X scores are null at iteration %s' % k)\n",
    "                break\n",
    "            # 2) Deflation (in place)\n",
    "            # - regress Xk's on x_score\n",
    "            p = np.dot(Xk.T, t) / (np.dot(t.T, t) + np.finfo(np.double).eps)\n",
    "            # - subtract rank-one approximations to obtain remainder matrix\n",
    "            Xk -= np.dot(t, p.T)\n",
    "# TO THINK HOW TO CHANGE TILDE Y\n",
    "            # - regress Yk's on x_score, then subtract rank-one approx.\n",
    "            q = (np.dot(Yk.T, t) / np.dot(t.T, t))\n",
    "            Yk -= np.dot(t, q.T)\n",
    "            # 3) Store weights, scores and loadings # Notation:\n",
    "            self.T[:, k] = t.ravel()  # T\n",
    "            self.U[:, k] = u.ravel()  # U\n",
    "            self.W[:, k] = w.ravel()  # W\n",
    "            self.C[:, k] = c.ravel()  # C\n",
    "            self.P[:, k] = p.ravel()  # P\n",
    "            self.Q[:, k] = q.ravel()  # Q\n",
    "        # Such that: X = TP' + Err and Y = UQ' + Err\n",
    "\n",
    "        # 4) rotations from input space to transformed space (scores)\n",
    "        # T = X W(P'W)^-1 = XW* (W* : p x k matrix)\n",
    "        # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)\n",
    "        self.x_rotations_ = np.dot(\n",
    "            self.W, linalg.pinv2(np.dot(self.P.T, self.W), **pinv2_args))\n",
    "        if Y.shape[1] > 1:\n",
    "            self.y_rotations_ = np.dot(\n",
    "                self.C, linalg.pinv2(np.dot(self.Q.T, self.C), **pinv2_args))\n",
    "        else:\n",
    "            self.Q = np.ones(1)\n",
    "\n",
    "        # Estimate regression coefficient\n",
    "        # Regress Y on T\n",
    "        # Y = TQ' + Err,\n",
    "        # Then express in function of X\n",
    "        # Y = X W(P'W)^-1Q' + Err = XB + Err\n",
    "        # => B = W*Q' (p x q)\n",
    "        self.coef_ = np.dot(self.P, self.Q.T)\n",
    "        self.coef_ = (1. / self.x_std_.reshape((p, 1)) * self.coef_ *\n",
    "                      self.y_std_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        \"\"\"Apply the dimension reduction learned on the train data.\n",
    "\n",
    "        x_scores if Y is not given, (x_scores, y_scores) otherwise.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'x_mean_')\n",
    "        X = check_array(X, copy=True, dtype=FLOAT_DTYPES)\n",
    "        # Normalize\n",
    "        X -= self.x_mean_\n",
    "        X /= self.x_std_\n",
    "        # Apply rotation\n",
    "        T = np.dot(X, self.P)\n",
    "        if Y is not None:\n",
    "            Y = check_array(Y, ensure_2d=False, copy=True, dtype=FLOAT_DTYPES)\n",
    "            if Y.ndim == 1:\n",
    "                Y = Y.reshape(-1, 1)\n",
    "# G?\n",
    "            Y -= self.y_mean_\n",
    "            Y /= self.y_std_\n",
    "# MB TILDE Y\n",
    "            y_scores = np.dot(Y, self.Q)\n",
    "            return T, U\n",
    "\n",
    "        return T\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Apply the dimension reduction learned on the train data.\n",
    "        \n",
    "        This call requires the estimation of a p x q matrix, which may\n",
    "        be an issue in high dimensional space.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'x_mean_')\n",
    "        X = check_array(X, copy=True, dtype=FLOAT_DTYPES)\n",
    "        # Normalize\n",
    "        X -= self.x_mean_\n",
    "        X /= self.x_std_\n",
    "        Ypred = np.dot(X, self.coef_)\n",
    "        return Ypred + self.y_mean_\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        \"\"\"\n",
    "        Learn and apply the dimension reduction on the train data.\n",
    "\n",
    "        x_scores if Y is not given, (x_scores, y_scores) otherwise.\n",
    "        \"\"\"\n",
    "        return self.fit(X, y, **fit_params).transform(X, y)\n",
    "\n",
    "\n",
    "class PLSRegression(_PLS):\n",
    "    \"\"\"\n",
    "    PLS regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components=2,max_iter=500, tol=1e-06):\n",
    "        super(PLSRegression, self).__init__(\n",
    "            n_components=n_components, max_iter=max_iter, tol=tol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
